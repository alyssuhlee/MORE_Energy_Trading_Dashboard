{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# URL of website\n",
    "url = 'https://embi.iemop.ph/t/tod/views/SYSTEM_ADVISORY/SOADVISORIES?%3AshowAppBanner=false&%3Adisplay_count=n&%3AshowVizHome=n&%3Aorigin=viz_share_link&%3AisGuestRedirectFromVizportal=y&%3Aembed=y'\n",
    "# Opening the website\n",
    "driver.get(url) \n",
    "# Maximize window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click 'Download'\n",
    "driver.find_element(By.XPATH, \"/html/body/div[2]/div[2]/div[2]/div[1]/div[2]/div[2]\").click()\n",
    "time.sleep(5)\n",
    "# Click 'Crosstab'\n",
    "driver.find_element(By.XPATH, \"/html/body/div[6]/div/div/div/div/div[2]/div/button[3]\").click()\n",
    "time.sleep(5)\n",
    "# Click 'Download'\n",
    "driver.find_element(By.XPATH, '/html/body/div[7]/div/div/div/div/div[2]/div/div[2]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = glob.glob(r'C:\\Users\\aslee\\Downloads\\*')\n",
    "# Finds the most recently created file from a list of files\n",
    "csv_file_path = max(list_of_files, key=os.path.getctime)\n",
    "final_csv_file_path = r'C:\\Users\\aslee\\Downloads\\SO_ADV_crosstab.csv'\n",
    "\n",
    "for i in range(1, 100000):\n",
    "    if csv_file_path == rf'C:\\Users\\aslee\\Downloads\\SO_ADV_crosstab ({i}).csv':\n",
    "        # os.replace(source, dest)\n",
    "        os.replace(csv_file_path, final_csv_file_path)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Header: ['TIME_MESSAGE', 'MESSAGE', 'REGION']\n",
      "Expected columns based on header: 3\n"
     ]
    }
   ],
   "source": [
    "# Check expected columns based on header\n",
    "def inspect_csv(file_path, encoding='utf-16', delimiter='\\t'):\n",
    "    with open(file_path, 'r', encoding=encoding) as infile:\n",
    "        reader = csv.reader(infile, delimiter=delimiter)\n",
    "        header = next(reader)\n",
    "        \n",
    "        # Clean the header by removing empty strings and stripping whitespace\n",
    "        header = [col.strip() for col in header if col.strip()]\n",
    "        expected_columns = len(header)\n",
    "        \n",
    "        print(f\"Cleaned Header: {header}\")\n",
    "        print(f\"Expected columns based on header: {expected_columns}\")\n",
    "        \n",
    "        return expected_columns, header\n",
    "\n",
    "# Usage\n",
    "expected_columns, header = inspect_csv(final_csv_file_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(file_path, cleaned_file_path, encoding='utf-16', delimiter='\\t', expected_columns=None):\n",
    "    with open(file_path, 'r', encoding=encoding) as infile:\n",
    "        reader = csv.reader(infile, delimiter=delimiter)\n",
    "        data = list(reader)\n",
    "        \n",
    "        if expected_columns is None:\n",
    "            expected_columns = len(data[0])\n",
    "        \n",
    "        cleaned_data = []\n",
    "        for i, row in enumerate(data):\n",
    "            if len(row) > expected_columns:\n",
    "                # Adjust the row to have the expected number of columns\n",
    "                new_row = row[:expected_columns-1] + [' '.join(row[expected_columns-1:])]\n",
    "                cleaned_data.append(new_row)\n",
    "            elif len(row) < expected_columns:\n",
    "                # Handle rows with fewer columns (e.g., append empty strings)\n",
    "                new_row = row + [''] * (expected_columns - len(row))\n",
    "                cleaned_data.append(new_row)\n",
    "            else:\n",
    "                cleaned_data.append(row)\n",
    "    \n",
    "    # Write cleaned data to a new file\n",
    "    with open(cleaned_file_path, 'w', encoding=encoding, newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=delimiter)\n",
    "        writer.writerow(header)  # Write the cleaned header first\n",
    "        writer.writerows(cleaned_data[1:])  # Write the data rows\n",
    "\n",
    "# Usage\n",
    "cleaned_csv_file_path = r'C:\\Users\\aslee\\Downloads\\cleaned_output_file.csv'\n",
    "clean_csv(final_csv_file_path, cleaned_csv_file_path, encoding='utf-16', delimiter='\\t', expected_columns=expected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_MESSAGE</th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>REGION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/24/2024 8:54:02 AM</td>\n",
       "      <td>Luzon Grid-07/24/2024 08:54: Tayabas-San Jose ...</td>\n",
       "      <td>CLUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/24/2024 8:42:46 AM</td>\n",
       "      <td>Luzon Grid-07/24/2024 08:43: Tayabas-San Jose ...</td>\n",
       "      <td>CLUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/24/2024 8:12:25 AM</td>\n",
       "      <td>Luzon Grid-07/24/2024 08:12: SCPC 3 tripped wi...</td>\n",
       "      <td>CLUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/24/2024 7:31:03 AM</td>\n",
       "      <td>Luzon Grid-07/24/2024 07:31: Tayabas-San Jose ...</td>\n",
       "      <td>CLUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/24/2024 7:29:14 AM</td>\n",
       "      <td>Luzon Grid-07/24/2024 07:29: Tayabas-San Jose ...</td>\n",
       "      <td>CLUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7/24/2024 5:43:43 AM</td>\n",
       "      <td>[NSO Update] Mindanao Grid-07/24/2024 05:50: G...</td>\n",
       "      <td>CMIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7/24/2024 5:42:16 AM</td>\n",
       "      <td>[NSO Update] Visayas Grid-07/24/2024 05:42: GR...</td>\n",
       "      <td>CVIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7/24/2024 5:38:21 AM</td>\n",
       "      <td>[NSO Update] Luzon Grid-07/24/2024 05:38: GRID...</td>\n",
       "      <td>CLUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7/24/2024 4:35:38 AM</td>\n",
       "      <td>[NSO Update] Luzon Grid-07/24/2024 04:35: Weat...</td>\n",
       "      <td>CLUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7/24/2024 4:33:53 AM</td>\n",
       "      <td>[NSO Update] Visayas Grid-07/24/2024 04:34: We...</td>\n",
       "      <td>CVIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIME_MESSAGE                                            MESSAGE  \\\n",
       "0  7/24/2024 8:54:02 AM  Luzon Grid-07/24/2024 08:54: Tayabas-San Jose ...   \n",
       "1  7/24/2024 8:42:46 AM  Luzon Grid-07/24/2024 08:43: Tayabas-San Jose ...   \n",
       "2  7/24/2024 8:12:25 AM  Luzon Grid-07/24/2024 08:12: SCPC 3 tripped wi...   \n",
       "3  7/24/2024 7:31:03 AM  Luzon Grid-07/24/2024 07:31: Tayabas-San Jose ...   \n",
       "4  7/24/2024 7:29:14 AM  Luzon Grid-07/24/2024 07:29: Tayabas-San Jose ...   \n",
       "5  7/24/2024 5:43:43 AM  [NSO Update] Mindanao Grid-07/24/2024 05:50: G...   \n",
       "6  7/24/2024 5:42:16 AM  [NSO Update] Visayas Grid-07/24/2024 05:42: GR...   \n",
       "7  7/24/2024 5:38:21 AM  [NSO Update] Luzon Grid-07/24/2024 05:38: GRID...   \n",
       "8  7/24/2024 4:35:38 AM  [NSO Update] Luzon Grid-07/24/2024 04:35: Weat...   \n",
       "9  7/24/2024 4:33:53 AM  [NSO Update] Visayas Grid-07/24/2024 04:34: We...   \n",
       "\n",
       "  REGION  \n",
       "0  CLUZ   \n",
       "1  CLUZ   \n",
       "2  CLUZ   \n",
       "3  CLUZ   \n",
       "4  CLUZ   \n",
       "5  CMIN   \n",
       "6  CVIS   \n",
       "7  CLUZ   \n",
       "8  CLUZ   \n",
       "9  CVIS   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the cleaned CSV file\n",
    "df = pd.read_csv(cleaned_csv_file_path, encoding='utf-16', delimiter='\\t')\n",
    "df.head(10) # Return the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aslee\\AppData\\Local\\Temp\\ipykernel_18088\\2967220205.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df.applymap(remove_problematic_characters)\n"
     ]
    }
   ],
   "source": [
    "# Function to remove specific problematic characters\n",
    "def remove_problematic_characters(text):\n",
    "    # Replace the problematic character \\x02 (hex) or \u0002 (unicode) with an empty string\n",
    "    return text.replace('\\x02', '').replace('\u0002', '')\n",
    "\n",
    "# Clean each cell in the DataFrame\n",
    "df_cleaned = df.applymap(remove_problematic_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"C:\\Users\\aslee\\Downloads\\cleaned_output_file.csv\" successfully converted to Excel file \"C:\\Users\\aslee\\OneDrive - MORE ELECTRIC AND POWER CORPORATION\\Desktop\\DASHBOARD_FINAL\\SO_ADVISORIES.xlsx\"\n"
     ]
    }
   ],
   "source": [
    "# Write the cleaned DataFrame to an Excel file\n",
    "excel_file_path = r'C:\\Users\\aslee\\OneDrive - MORE ELECTRIC AND POWER CORPORATION\\Desktop\\DASHBOARD_FINAL\\SO_ADVISORIES.xlsx'\n",
    "df_cleaned.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f'CSV file \"{cleaned_csv_file_path}\" successfully converted to Excel file \"{excel_file_path}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
